{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS470 Introduction to Artificial Intelligence\n",
    "## Deep Learning Practice\n",
    "#### TA. Jonghwa Lee / jongwhoa.lee@kaist.ac.kr\n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4. Image classification using CNN\n",
    "\n",
    "In this notebook, we will implement a convolutional neural network (CNN) to classify cats or dogs from image. It builds an image classifier using a `tf.keras.Sequential` model and load data using [`tf.keras.preprocessing.image.ImageDataGenerator`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator). ImageDataGenerator class will be used for building _data input pipelines_ to efficiently work with data on disk to use with the model. Besides, this will be used for _data augmentation_ as a technique to fight overfitting in computer vision tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dataset\n",
    "\n",
    "Let's begin by downloading the cats and dogs images. In this practice, we are going to use a filtered version of [Dogs vs Cats](https://www.kaggle.com/c/dogs-vs-cats/data) dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "# Basically, data will be stored in ~/.keras/dataset/\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has the following directory structure:\n",
    "\n",
    "cats_and_dogs_filtered  \n",
    "|__ train  \n",
    "&emsp;|____________ cats: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]  \n",
    "&emsp;|____________ dogs: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]  \n",
    "|__ validation  \n",
    "&emsp;|____________ cats: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]  \n",
    "&emsp;|____________ dogs: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many cats and dogs images are in the training and validation directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "total_train = num_cats_tr + num_dogs_tr\n",
    "total_val = num_cats_val + num_dogs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total training cat images:', num_cats_tr)\n",
    "print('Total training dog images:', num_dogs_tr)\n",
    "\n",
    "print('Total validation cat images:', num_cats_val)\n",
    "print('Total validation dog images:', num_dogs_val)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, set up variables to use while pre-processing the dataset and training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset\n",
    "To feed the images to the network, we first transform the images into appropriately **pre-processed floating point tensors**:\n",
    "\n",
    "1. Read images from the disk.\n",
    "1. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
    "1. Convert them into floating point tensors.\n",
    "1. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
    "\n",
    "Fortunately, all these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`. It can read images from disk and **preprocess them into proper tensors**. It will also set up generators that **convert these images into batches** of tensors—helpful when training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# TODO: Define the generators for training and validation images with rescaling factor\n",
    "train_image_generator = \n",
    "validation_image_generator = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `flow_from_directory()` method, let's load images from the disk, apply rescaling, and resize the images into the required dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load training images from the disk\n",
    "train_data_gen = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load validation images from the disk\n",
    "val_data_gen = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the dataset\n",
    "Let's visualize the training images by extracting a batch of images from the training generator—which is 128 images in this notebook—then plot five of them with `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_data_gen)\n",
    "print(\"shape of sample_training_images =\", sample_training_images.shape)\n",
    "print(\"dtype of sample_training_images =\", sample_training_images.dtype)\n",
    "print(\"max of sample_training_images =\", sample_training_images.max())\n",
    "print(\"min of sample_training_images =\", sample_training_images.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `next()` function returns a batch from the dataset. The return value of `next()` function is in form of `(x_train, y_train)` where `x_train` is training features and `y_train`, its labels. We will discard the labels here to only visualize the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model \n",
    "Let's define a convolutional neural network which consists of three convolution blocks with a max pool layer in each of them. After them, we will add a fully connected layer with 512 units that is activated by a `relu` function. And then, we will add the last fully connected layer with 1 neuron that is activated by a `sigmoid` function to produce a class probability based on binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define a convolutional neural networks using tf.keras.Sequential\n",
    "model = tf.keras.Sequential([\n",
    "    # TODO: Add a convolution block with filters=16, kernel_size=3, padding='same' and activation='relu'\n",
    "    \n",
    "    # TODO: Add a max pool layer\n",
    "    \n",
    "    \n",
    "    # TODO: Add a convolution block with filters=32, kernel_size=3, padding='same' and activation='relu'\n",
    "    \n",
    "    # TODO: Add a max pool layer\n",
    "    \n",
    "    \n",
    "    # TODO: Add a convolution block with filters=64, kernel_size=3, padding='same' and activation='relu'\n",
    "    \n",
    "    # TODO: Add a max pool layer\n",
    "    \n",
    "    \n",
    "    # TODO: Add a flatten layer\n",
    "   \n",
    "    # TODO: Add a fully-connected layer with 512 units activated by relu\n",
    "    \n",
    "    \n",
    "    # TODO: Add a fully-connected layer with 1 unit activated by sigmoid\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "Let's compile the model using the adam optimizer and binary cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model with the following parameters:\n",
    "# - optimizer: adam\n",
    "# - loss: binary crossentropy\n",
    "# - metrics: accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model \n",
    "Since we have loaded the dataset using `ImageDataGenerator()`, we should train the model using the `fit()` method.\n",
    "\n",
    "- `steps_per_epoch`: Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch.   \n",
    "- `validation_steps`:  Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model using `fit()`\n",
    "history = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize training results\n",
    "Let's visualize the results after training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plots, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 70% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable. Thus, we can think that this is the overfitting problem as we checked in previous class. \n",
    "\n",
    "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples—to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as _overfitting_. It means that the model will have a difficult time generalizing on a new dataset.\n",
    "\n",
    "There are multiple ways to fight overfitting in the training process. In this notebook, we'll use *data augmentation* and add *dropout* to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation\n",
    "Overfitting generally occurs when there are a small number of training examples. One way to fix this problem is to augment the dataset so that it has a sufficient number of training examples. Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better.\n",
    "\n",
    "Since `ImageDataGenerator` supports a lot of transformations, we can easily augment the dataset and it will take care of applying it during the training process.\n",
    "\n",
    "- `ImageDataGenerator`\n",
    "    - featurewise_center\n",
    "    - samplewise_center\n",
    "    - featurewise_std_normalization\n",
    "    - samplewise_std_normalization\n",
    "    - zca_epsilon\n",
    "    - zca_whitening\n",
    "    - rotation_range\n",
    "    - width_shift_range\n",
    "    - height_shift_range\n",
    "    - brightness_range\n",
    "    - shear_range\n",
    "    - zoom_range\n",
    "    - fill_mode\n",
    "    - cval\n",
    "    - horizontal_flip\n",
    "    - vertical_flip\n",
    "    - preprocessing_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Horizontal flip\n",
    "\n",
    "Pass `horizontal_flip` as an argument to the `ImageDataGenerator` class and set it to True to apply this augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create `ImageDataGenerator` which applies horizontal flip\n",
    "image_gen = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take one sample image from the training examples and repeat it five times so that the augmentation is applied to the same image five times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random rotation\n",
    "Let's take a look at a different augmentation called rotation and apply 45 degrees of rotation randomly to the training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create `ImageDataGenerator` which applies random rotation\n",
    "image_gen = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zoom\n",
    "Apply a zoom augmentation to the dataset to zoom images up to 50% randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create `ImageDataGenerator` which applies zoom\n",
    "image_gen = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Put it all together\n",
    "Let's apply all the above augmentations. Here, we also applied `rescale`, `width shift` and `height shift` augmentation to the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create `ImageDataGenerator` which applies rescale, rotation, width shift, height shift, horizontal flip and zoom\n",
    "image_gen_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how a single image would look five different times when passing these augmentations randomly to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the validation data generator\n",
    "Generally, we only apply data augmentation to the training examples. Therefore, we will only rescale the validation images and convert them into batches using `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_val = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=validation_dir,\n",
    "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a new network with dropouts\n",
    "Here, we will apply dropout to first and last max pool layers with dropout rate of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define a convolutional neural networks using tf.keras.Sequential\n",
    "model_new = tf.keras.Sequential([\n",
    "    \n",
    "    # TODO: Add a convolution block with filters=16, kernel_size=3, padding='same' and activation='relu'\n",
    "    \n",
    "    # TODO: Add a max pool layer\n",
    "    \n",
    "    # TODO: Add a dropout layer with rate of 0.2\n",
    "    \n",
    "\n",
    "    # TODO: Add a convolution block with filters=32, kernel_size=3, padding='same' and activation='relu'\n",
    "    \n",
    "    # TODO: Add a max pool layer\n",
    "    \n",
    "    \n",
    "    # TODO: Add a convolution block with filters=64, kernel_size=3, padding='same' and activation='relu'\n",
    "    \n",
    "    # TODO: Add a max pool layer\n",
    "    \n",
    "    # TODO: Add a dropout layer with rate of 0.2\n",
    "    \n",
    "    \n",
    "    # TODO: Add a flatten layer\n",
    "    \n",
    "    # TODO: Add a fully-connected layer with 512 units activated by relu\n",
    "    \n",
    "    \n",
    "    # TODO: Add a fully-connected layer with 1 unit activated by sigmoid\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "After introducing dropouts to the network, compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model with the following parameters:\n",
    "# - optimizer: adam\n",
    "# - loss: binary crossentropy\n",
    "# - metrics: accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "After successfully introducing data augmentations to the training examples and adding dropouts to the network, train this new network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model using `fit()`\n",
    "history = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the model\n",
    "Let's visualize the performance trend of the new model after training, we can see that there is significantly less overfitting than before. The accuracy should go up after training the model for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train more epoch\n",
    "\n",
    "![train 50 epoch](images/train-50-epoch.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
