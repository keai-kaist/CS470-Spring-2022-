{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS470 Introduction to Artificial Intelligence\n",
    "## Deep Learning Practice \n",
    "#### TA. Jinsu Lim\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. Save and restore models\n",
    "\n",
    "#### Topics for this chapter\n",
    " * Saving weights during training\n",
    " * Restoring the saved model\n",
    " * Saving manually\n",
    " * Saving/loading the entire model\n",
    " ---\n",
    "\n",
    "Model progress can be saved during—and after—training. This means that a model can resume where it ended the training and resume at that point. Saving also means you can share your model and others can recreate or reproduce your work. When publishing research models and ML techniques, most machine learning practitioners share:\n",
    "- code to create the model\n",
    "- the trained weights, or parameters, for the model\n",
    "\n",
    "Sharing these data helps others understand how the model works and try it themselves with new or original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "\n",
    "Install and import TensorFlow and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "!pip install -q pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get an example dataset\n",
    "\n",
    "To demonstrate how to save and load weights, you'll use the MNIST dataset. To speed up these runs, we will use only the first 1000 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model \n",
    "Start by building a simple sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "      ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save checkpoints during training (Save weights only)\n",
    "\n",
    "When you have a _trained model_, you don't have to retrain it from the scratch. You can just pick-up training where you left off—in case the training process was interrupted. The callback function in [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ModelCheckpoint)  allows us to continually save the model during and at the end of training.\n",
    "\n",
    "#### Checkpoint callback usage\n",
    "Create a tf.keras.callbacks.ModelCheckpoint callback that **_saves weights only_** during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ckpt_path_for_t1 = \"checkpoints/training_1/cp.ckpt\"\n",
    "ckpt_dir_for_t1 = os.path.dirname(ckpt_path_for_t1)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path_for_t1,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # Pass callback to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a single collection of TensorFlow checkpoint files that are updated at the end of each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {ckpt_dir_for_t1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore to the untrained model\n",
    "\n",
    "Now let's rebuild a fresh and untrained model by calling `create_model()`. We can evaluate it on the test set in order to check that it is not trained. An untrained model will have very low accuracy (< 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic model instance\n",
    "new_model = create_model()\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this time, let's load the weights from the checkpoint and re-evaluate the test dataset. We can load the weights using `load_weights()`. Since they have the same model architecture, we can share weights despite that it's a different instance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the weights\n",
    "new_model.load_weights(ckpt_path_for_t1)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss,acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "#### Requirement for load weights\n",
    "\n",
    "When restoring a model from weights-only, we must have a model with the **same architecture as the original model**. When we restore weights to the model with different architecture, an error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a different sequential model\n",
    "def different_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(100, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "      ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "different_model = different_model()\n",
    "\n",
    "different_model.load_weights(ckpt_path_for_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "#### Manually save weights\n",
    "\n",
    "You saw how to load the weights into a model. Another way to save the weights is manually saving them by using `Model.save_weights()`. By default, `save_weights` in TensorFlow saves checkpoints format with a .ckpt extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/manual_checkpoint/cur_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls 'checkpoints/manual_checkpoint/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/manual_checkpoint/cur_weights')\n",
    "\n",
    "# Evaluate the model\n",
    "loss,acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "#### Save the entire model \n",
    "\n",
    "Not only weights, the entire model including optimizer and other settings can be saved to a single file. This allows us to export a model and use it without access to the original Python code for creating a model. Since the optimizer-state is recovered, we can resume training from exactly where we left off.\n",
    "\n",
    "We will save the entire model by using HDF5 file extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model as HDF5 file\n",
    "\n",
    "Keras provides a basic save format using the [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# Save the entire model to a HDF5 file\n",
    "save_dir = 'saved_models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "model.save(os.path.join(save_dir, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls saved_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "#### Restore the entire model\n",
    "\n",
    "Now, we will load the entire saved model by using `keras.models.load_model()`. We need a path for the saved model as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = keras.models.load_model(os.path.join(save_dir, 'my_model.h5'))\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "By checking the model's accuracy, we can check whether it is loaded well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "This **save the entire model** technique saves following attributes:\n",
    "\n",
    "- The weight values\n",
    "- The model's configuration (architecture)\n",
    "- The optimizer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_model.optimizer)\n",
    "print(new_model.loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
