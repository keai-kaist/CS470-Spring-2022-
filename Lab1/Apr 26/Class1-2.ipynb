{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxdnP3UIF525"
   },
   "source": [
    "# CS470 인공지능개론\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cO9XsNIF52_"
   },
   "source": [
    "# Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUxyTAHGF52_"
   },
   "source": [
    "1. **Basic of Tensorflow**  \n",
    "    1-1. Introduction to Tensorflow  \n",
    "    1-2. Tensors and operations based on eager execution  \n",
    "    1-3. Neural networks in TensorFlow \n",
    "    \n",
    "1. **MLP-based Classification**   \n",
    "    2-1. Image classification  \n",
    "    2-2. Text classification  \n",
    "    2-3. Overfitting and how to fight it  \n",
    "    2-4. Save and restore models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhiEciEPF53A"
   },
   "source": [
    "## 1. Basic of Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Introduction to Tensorflow  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5oQ48AsF53A"
   },
   "source": [
    "\n",
    "\n",
    "- [**TensorFlow**](https://www.tensorflow.org) is a software library, developed by Google Brain Team within Google's Machine Learning Intelligence research organization, for the purposes of conducting machine learning and deep neural network research.\n",
    "- TensorFlow combines the computational algebra of compilation optimization techniques, making easy the calculation of many mathematical expressions that would be difficult to calculate, instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNVy4tZVF53D"
   },
   "source": [
    "#### Main features\n",
    "* Defining, optimizing, and efficiently calculating mathematical expressions involving multi-dimensional arrays (tensors).\n",
    "* Programming support of **deep neural networks** and machine learning techniques.\n",
    "* Transparent use of GPU computing, automating management and optimization of the same memory and the data used. You can write the same code and run it either on CPUs or GPUs. More specifically, TensorFlow will figure out which parts of the computation should be moved to the GPU.\n",
    "* High scalability of computation across machines and huge data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxAJ-zmYF53E"
   },
   "source": [
    "### 1-2. Tensors and operations based on eager execution\n",
    "\n",
    "TensorFlow is called TensorFlow because it handles the flow (node/mathematical operation) of Tensors (data), which you can think of as multidimensional arrays. In TensorFlow, computations can be thought of as graphs. In the previous version (≤1.15) of Tensorflow, we implemented a computation graph thought a session we defined and ran the graphs in the session. But, the latest version does not use the session, it can be used simply through an eager executation.\n",
    "\n",
    "[**Eager execution**](https://www.tensorflow.org/guide/eager) is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKpJQVrKF53E"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "print('Tensorflow: ', tf.__version__)\n",
    "\n",
    "import cProfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "_6mbRAGpF53F"
   },
   "outputs": [],
   "source": [
    "# In Tensorflow 2.0, eager execution is enabled by default.\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdsDVQOxF53G"
   },
   "source": [
    "Now, let's define simple computation graph under the eager execution:\n",
    "\n",
    "![Computation Graph - Add Operation](https://i.imgur.com/K34aWFr.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "a6xPXJU4F53G"
   },
   "outputs": [],
   "source": [
    "# TODO: Using the eager execution, create the nodes in the graph, then check the output\n",
    "a = \n",
    "b = \n",
    "c = \n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnD-mB9VF53G"
   },
   "source": [
    "Notice how we've created a computation graph consisting of TensorFlow operations, and how the output is a Tensor with value 76 -- we've just created a computation graph consisting of operations, and it's executed them and given us back the result. That's because of Eager!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irQiEK8-F53G"
   },
   "source": [
    "#### Not eager execution (FYI)\n",
    "```python\n",
    "a = tf.constant(1, name='a')\n",
    "b = tf.constant(2, name='b')\n",
    "c = tf.add(a, b, name='c')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0jI6kwpF53G"
   },
   "source": [
    "#### Tensor\n",
    "A **tensor** is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmOVOP5GF53H"
   },
   "source": [
    "#### 1-D Tensor (Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "0NN-Mxr6F53H"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "pprint = partial(print, end='\\n\\n')\n",
    "\n",
    "tensor_1d = tf.constant([1, 2.5, 4.6, 5.75, 9.7], dtype=tf.float64, name='tensor_1d')\n",
    "print('tensor_1d =', tensor_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMmSUT4QVSEY"
   },
   "source": [
    "You can convert a tensor to a NumPy array either using np.array or the tensor.numpy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0k_EUrWHVRjK"
   },
   "outputs": [],
   "source": [
    "numpy_1d = tensor_1d.numpy()\n",
    "print(\"numpy_1d =\", numpy_1d)\n",
    "\n",
    "tensor_1d = tf.constant(numpy_1d)\n",
    "print(\"tensor_1d =\", tensor_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lan7E2WUF53H"
   },
   "source": [
    "#### 2-D Tensor (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fTlU6Ke9F53H"
   },
   "outputs": [],
   "source": [
    "tensor_2d = tf.constant(np.arange(16).reshape(4, 4), dtype=tf.float64, name='tensor_2d')\n",
    "print('tensor_2d =', tensor_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVMpEUPEVWlF"
   },
   "outputs": [],
   "source": [
    "tensor_2d.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qthmPMvqF53H"
   },
   "source": [
    "#### Basic operations in Tensorflow\n",
    "You can run TensorFlow operations and the results will return immediately because of eager execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUlD9F4FF53H"
   },
   "outputs": [],
   "source": [
    "A = tf.constant([\n",
    "    [4, 3],\n",
    "    [1, 1],\n",
    "], dtype=tf.float32, name='A')\n",
    "\n",
    "B = tf.constant([\n",
    "    [3, 5],\n",
    "    [1, 2],\n",
    "], dtype=tf.float32, name='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMrU1TVsF53I"
   },
   "source": [
    "`tf.reduce_sum`: Computes the sum of elements across dimensions of a tensor. (deprecated arguments) <br>\n",
    "`tf.linalg.det`: Computes the determinant of one or more square matrices. <br>\n",
    "    (e.g. if given matrix is [[a, b], [c, d]], the output of this matrix is ad-bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "HGMak_wEF53I"
   },
   "outputs": [],
   "source": [
    "pprint('A + B =', )\n",
    "pprint('A - B =', )\n",
    "pprint('A ⨉ B =', )\n",
    "pprint('A² =', )\n",
    "pprint('sum(A) =', )\n",
    "pprint('inv(A) =', )\n",
    "pprint('A ⨉ inv(A) =', )\n",
    "print('det(A) =', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqITNKIYVtg5"
   },
   "source": [
    "#### Introduction to Variables\n",
    "\n",
    "A TensorFlow variable is the recommended way to represent shared, persistent state your program manipulates. \n",
    "\n",
    "Variables are created and tracked via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like tf.keras use tf.Variable to store model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oki0CFDRWAue"
   },
   "source": [
    "#### Create a variable\n",
    "\n",
    "To create a variable, provide an initial value. The tf.Variable will have the same dtype as the initialization value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTL87aJVVrT6"
   },
   "outputs": [],
   "source": [
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "my_variable = tf.Variable(my_tensor)\n",
    "\n",
    "# Variables can be all kinds of types, just like tensors\n",
    "bool_variable = tf.Variable([False, False, False, True])\n",
    "complex_variable = tf.Variable([5 + 4j, 6 + 1j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znM7KkhMWFW5"
   },
   "source": [
    "A variable looks and acts like a tensor, and, in fact, is a data structure backed by a tf.Tensor. Like tensors, they have a dtype and a shape, and can be exported to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArJtH-7mVyH9"
   },
   "outputs": [],
   "source": [
    "print(\"Shape: \", my_variable.shape)\n",
    "print(\"DType: \", my_variable.dtype)\n",
    "print(\"As NumPy: \", my_variable.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S45yj0kMWK3m"
   },
   "source": [
    "Most tensor operations work on variables as expected, although variables cannot be reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VTmgkTHWMun"
   },
   "outputs": [],
   "source": [
    "print(\"A variable:\", my_variable)\n",
    "print(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_variable))\n",
    "print(\"\\nIndex of highest value:\", tf.argmax(my_variable))\n",
    "\n",
    "# This creates a new tensor; it does not reshape the variable.\n",
    "print(\"\\nCopying and reshaping: \", tf.reshape(my_variable, ([1,4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SolvTDBF53I"
   },
   "source": [
    "#### Handling tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3brVXGZF53I"
   },
   "outputs": [],
   "source": [
    "import urllib.request as urllib2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a file-like object from the url\n",
    "f = urllib2.urlopen(\"http://matplotlib.sourceforge.net/_static/logo2.png\")\n",
    "\n",
    "# read the image file in a numpy array\n",
    "image = plt.imread(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "iNmdsrw2F53J"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(\"shape of image =\",image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RVj0hVSF53J"
   },
   "source": [
    "`tf.slice(input_,begin,size,name=None)`: Extract a slice of _size_ from a tensor input starting at the location specified by _begin_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "_LddUDjGF53J"
   },
   "outputs": [],
   "source": [
    "print('Slice the tensor')\n",
    "sliced = tf.slice(image, [50, 0, 0], [50, 300, -1]) # input, begin, size\n",
    "plt.imshow(sliced)\n",
    "plt.show()\n",
    "print(image.shape)\n",
    "print(sliced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1PIjAR1HFbQ"
   },
   "outputs": [],
   "source": [
    "print(\"shape of image =\", image.shape)\n",
    "print(\"shape of sliced image =\", sliced.shape)\n",
    "print(\"type of image =\", type(image))\n",
    "print(\"type of sliced image =\", type(sliced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4ab3XA0F53J"
   },
   "source": [
    "`tf.transpose(a,perm=None,name='transpose',conjugate=False)`: Transposes _a_. Permutes the dimensions according to _perm_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "b6QB5lUiF53J"
   },
   "outputs": [],
   "source": [
    "print('Transepose the tensor')\n",
    "transposed = tf.transpose(image, perm=[1, 0, 2])\n",
    "plt.imshow(transposed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oLFcuY9F53K"
   },
   "source": [
    "### 1-3. Neural networks in TensorFlow\n",
    "\n",
    "We can define neural networks in TensorFlow, and it's often helpful to think about this using the idea of computation graphs. TensorFlow uses a high-level API called [Keras](https://www.tensorflow.org/guide/keras) that provides a powerful, intuitive framework for building and training deep learning models. In this lecture, we'll be using the Keras API to build and train our models.\n",
    "\n",
    "Let's consider this example of a very simple neural network of just one dense layer:\n",
    "\n",
    "<img src=\"https://i.imgur.com/NxfQgpy.png\" width=\"600\">\n",
    "\n",
    "This graph takes an input `x` and computes an output `out = sigmoid(W * x + b)`. \n",
    "\n",
    "First, let's define this computation graph in TensorFlow via a simple function, as we did before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgJjPN2e1ZTu"
   },
   "source": [
    "tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None, name=None): Outputs random values from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mz1-HBsZF53L"
   },
   "outputs": [],
   "source": [
    "# n_in: number of inputs\n",
    "# n_out: number of outputs\n",
    "def our_dense_layer(x, n_in, n_out):\n",
    "    # TODO: define and initialize parameters, a weight matrix W and biases b\n",
    "    #       x.shape = (..., n_in)\n",
    "    #       W.shape = (n_in, n_out)\n",
    "    #       b.shape = (1, n_out)\n",
    "    W = \n",
    "    b = \n",
    "    \n",
    "    # TODO: define the operati0on for z (hint: use tf.matmul)\n",
    "    z = \n",
    "\n",
    "    # TODO: define the operation for out (hint: use tf.sigmoid)\n",
    "    out = \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYQOfpCeF53L"
   },
   "source": [
    "Then, we can define an example input, feed it into `our_dense_layer` function, and immediately execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "FHYslBnlF53L"
   },
   "outputs": [],
   "source": [
    "# define an example input (x_input)\n",
    "x_input = tf.constant([[1.0, 2.0]])\n",
    "\n",
    "# TODO: call `our_dense_layer` to get the output of the network\n",
    "print(our_dense_layer(x_input,2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WNbzpV5F53L"
   },
   "source": [
    "#### Tensorflow with Keras\n",
    "Now, instead of explicitly defining a simple function, we'll use the Keras API to define our neural network. This will be especially important as we move on to more complicated network architectures.\n",
    "\n",
    "Specifically, for this network we'll use the Keras Sequential model from the tf.keras API to define our network. The tf.keras.Sequential model lets us conveniently define a linear stack of network layers. We'll use tf.keras.layers.Dense to define our single fully connected network layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ymZoLgeF53L"
   },
   "outputs": [],
   "source": [
    "# Define the number of inputs and outputs\n",
    "n_input_nodes = 2\n",
    "n_output_nodes = 3\n",
    "\n",
    "# define a sequential model using Keras API\n",
    "model = tf.keras.Sequential()\n",
    "# define a dense (fully connected) layer to compute z using Keras API \n",
    "dense_layer = tf.keras.layers.Dense(n_output_nodes, input_shape=(n_input_nodes,), activation='sigmoid')\n",
    "# add the dense layer to the model\n",
    "model.add(dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "d_D1Wj1aF53M"
   },
   "outputs": [],
   "source": [
    "# define an example input (x_input)\n",
    "x_input = tf.constant([[1.0, 2.0]])\n",
    "\n",
    "# feed the input into `model` and get the output\n",
    "print(model(x_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YytIvC0nJGa"
   },
   "source": [
    "### Why Tensorflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b54QzdXpnNIS"
   },
   "source": [
    "On a typical system, there are multiple computing devices. \n",
    "\n",
    "In TensorFlow, the supported device types are **CPU** and **GPU**. \n",
    "\n",
    "They are represented as strings. For example:\n",
    "\n",
    "* `'/cpu:0'`: The CPU of your machine.\n",
    "* `'/gpu:0'`: The GPU of your machine, if you have one.\n",
    "* `'/gpu:1'`: The second GPU of your machine, etc.\n",
    "    \n",
    "If a TensorFlow operation has both **CPU** and **GPU** implementations, the GPU devices will be given priority when the operation is assigned to a device. \n",
    "\n",
    "For example, `matmul` has both CPU and GPU kernels. On a system with devices `cpu:0` and `gpu:0`, `gpu:0` will be selected to run `matmul`.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DF_Pa9-nQRR"
   },
   "source": [
    "#### Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgSWfWJMnTZh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "available_gpus = get_available_gpus()\n",
    "print(available_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xPJFxtinVEh"
   },
   "outputs": [],
   "source": [
    "c = []\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    for d in available_gpus:\n",
    "        with tf.device(d):\n",
    "            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n",
    "            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n",
    "            c.append(tf.matmul(a, b))\n",
    "            \n",
    "    with tf.device('/cpu:0'):\n",
    "        result = tf.add_n(c)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjgJarOVnWFp"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.random.normal((512, 64, 32, 32))\n",
    "    b = tf.random.normal((512, 64, 32, 32))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    tf.matmul(a, b)\n",
    "    end_time = time.time()\n",
    "\n",
    "print('Elapsed time: {:.4f}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sJbPGpjnXFh"
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.random.normal((512, 64, 32, 32))\n",
    "    b = tf.random.normal((512, 64, 32, 32))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    tf.matmul(a, b)\n",
    "    end_time = time.time()\n",
    "    \n",
    "print('Elapsed time: {:.4f}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qg04jZF53N"
   },
   "source": [
    "### More on Tensorflow\n",
    "\n",
    "[Official API Documentation](https://www.tensorflow.org/api_docs/python)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zxdnP3UIF525",
    "TNVy4tZVF53D"
   ],
   "name": "Class1-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
